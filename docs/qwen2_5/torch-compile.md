    最开始的时候写了一个脚本，未编译情况下先跑3次取平均值，再清空后创建编译后的模型类再跑3次，取平均值，两者进行比较。

    初始结果非常出人意料：

    没有 torch compile的qwen模型跑我的两个100KB图片平均需要14秒；
    加上 torch compile 和预热后平均变成了55秒，慢了三倍……

    经过了一番检查后发现，原来的清空缓存方式无法完全清空，导致第二个模型类创建时其中有一部分在使用CPU进行处理。同时不完全清空还可能导致显存泄漏 + WSL 内存管理问题。

```
del model
torch.cuda.empty_cache()
```

    更改成如下清空方式则可以完成清空：

```
def clean_cuda_state():
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.reset_peak_memory_stats()
        torch.cuda.synchronize()
        import gc
        gc.collect()
        torch.cuda._lazy_init()
```

    但是在清空之后出现了新的问题——使用了比较彻底的清理后第二次模型从14s变成了8s。而且如果先跑torch compile的qwen模型再跑没有编译的模型也是 14s 和 8s。

    也就是说出现了运行顺序决定推理速度的情况。

    后续进行batch_size修改、两次运行输入修改、max_new_tokens的修改都没有明显的结果变化，都是后面执行的模型推理要远快于该模型独自进行调用。

    

![](C:\Users\21391\AppData\Roaming\marktext\images\2025-10-21-21-31-17-98cc75ea-958b-4afa-bad1-63e73157997b.png)

d

![](C:\Users\21391\AppData\Roaming\marktext\images\2025-10-21-21-34-23-image.png)

d左下角的暗绿色cudaMemcpyAsync操作都是3.9ms，可以用来作为比例尺，发现右侧

经过了多次测试，可以确定在模型正式运行前，可以先临时创建一个模型变量并跑一次推理（输入不一定要相同，可以使用小输入, 但是与真实相近的输入可以获得更好的效果），效果会明显优于直接预热。



不使用“预热”：

```
 第 1 次运行: 23.116秒
 第 2 次运行: 22.436秒
 第 3 次运行: 20.362秒
 第 4 次运行: 20.831秒
 第 5 次运行: 22.145秒
平均耗时: 21.778秒

 第 1 次运行: 13.087秒
 第 2 次运行: 11.699秒
 第 3 次运行: 13.018秒
 第 4 次运行: 11.777秒
 第 5 次运行: 13.146秒
平均耗时: 12.545秒

性能对比结果
未编译版本: 21.778秒
编译版本: 12.545秒
加速比: 1.74x
性能提升: 42.4%
```



“预热”使用相同输入，相同 max_new_token 结果：

```
未编译：
 第 1 次运行: 12.007秒
 第 2 次运行: 13.898秒
 第 3 次运行: 12.688秒
平均耗时: 12.864秒

编译模式：
 第 1 次运行: 11.931秒
 第 2 次运行: 10.388秒
 第 3 次运行: 12.100秒
平均耗时: 11.473秒

性能对比结果：
未编译版本: 12.864秒
编译版本: 11.473秒
加速比: 1.12x
性能提升: 10.8%
```




“预热”使用相同输入，不同 max_new_token 结果：

```
未编译：
 第 1 次运行: 16.514秒
 第 2 次运行: 17.000秒
 第 3 次运行: 16.085秒
 第 4 次运行: 17.011秒
 平均耗时: 16.653秒

编译模式：
 第 1 次运行: 14.780秒
 第 2 次运行: 13.241秒
 第 3 次运行: 14.902秒
 第 4 次运行: 13.367秒
 平均耗时: 14.073秒

性能对比结果
未编译版本: 16.653秒
编译版本: 14.073秒
加速比: 1.18x
性能提升: 15.5%
```




“预热”使用不同输入，不同 max_new_token 结果：

```
未编译：
 第 1 次运行: 16.781秒
 第 2 次运行: 18.862秒
 第 3 次运行: 18.112秒
 第 4 次运行: 16.055秒
平均耗时: 17.453秒

编译模式：
 第 1 次运行: 12.720秒
 第 2 次运行: 14.311秒
 第 3 次运行: 14.103秒
 第 4 次运行: 15.246秒
平均耗时: 14.095秒

性能对比结果
未编译版本: 17.453秒
编译版本: 14.095秒
加速比: 1.24x
性能提升: 19.2%
```




三张图片，开启“预热”和正常预热（正常预热batch_size也设置为3）:

```



未编译版本: 17.974秒
编译版本:   20.179秒
加速比:     0.89x
性能提升:   -12.3%
```

三张图片，仅开启“预热”:

```
未编译版本: 17.859秒
编译版本:   16.051秒
加速比:     1.11x
性能提升:   10.1%
```

d
